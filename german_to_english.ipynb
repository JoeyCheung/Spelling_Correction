{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "from numpy import array, argmax, random, take\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, Bidirectional, RepeatVector, TimeDistributed\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is a text file of English-German sentence pairs. First we will read the file using the function defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read raw text file\n",
    "def read_text(filename):\n",
    "    # open the file\n",
    "    file = open(filename, mode='rt', encoding='utf-8')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define a function to split the text into English-German pairs separated by '\\n' and then split these pairs into English sentences and German sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a text into sentences\n",
    "def to_lines(text):\n",
    "    sents = text.strip().split('\\n')\n",
    "    sents = [i.split('\\t') for i in sents]\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Download the data from [here.](http://www.manythings.org/anki/deu-eng.zip)__ and extract \"deu.txt\" in your working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_text(\"deu.txt\")\n",
    "deu_eng = to_lines(data)\n",
    "deu_eng = array(deu_eng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual data contains over 150,000 sentence-pairs. However, we will use the first 50,000 sentence pairs only to reduce the training time of the model. You can change this number as per you system computation power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "deu_eng = deu_eng[:50000,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Cleaning\n",
    "\n",
    "Let's take a look at our data, then we will decide which pre-processing steps to adopt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Hi.', 'Hallo!',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #380701 (cburgmer)'],\n",
       "       ['Hi.', 'Grüß Gott!',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #659813 (Esperantostern)'],\n",
       "       ['Run!', 'Lauf!',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #941078 (Fingerhut)'],\n",
       "       ...,\n",
       "       ['I wholeheartedly agree.', 'Ich stimme rückhaltlos zu.',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1488273 (Spamster) & #1693172 (al_ex_an_der)'],\n",
       "       ['I will always love you.', 'Ich werde dich immer lieben.',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #853146 (piksea) & #395302 (xtofu80)'],\n",
       "       ['I will be back by nine.', 'Um neun bin ich wieder zurück.',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #72281 (CK) & #345033 (lilygilder)']],\n",
       "      dtype='<U537')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deu_eng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will get rid of the punctuation marks, and then convert the text to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CCBY 20 France Attribution tatoebaorg 538123 CM  380701 cburgmer',\n",
       "       'CCBY 20 France Attribution tatoebaorg 538123 CM  659813 Esperantostern',\n",
       "       'CCBY 20 France Attribution tatoebaorg 906328 papabear  941078 Fingerhut',\n",
       "       ...,\n",
       "       'CCBY 20 France Attribution tatoebaorg 1488273 Spamster  1693172 alexander',\n",
       "       'CCBY 20 France Attribution tatoebaorg 853146 piksea  395302 xtofu80',\n",
       "       'CCBY 20 France Attribution tatoebaorg 72281 CK  345033 lilygilder'],\n",
       "      dtype='<U537')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deu_eng[:, 2] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,2]]\n",
    "deu_eng[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "deu_eng[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,0]]\n",
    "deu_eng[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Hi', 'Hallo',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #380701 (cburgmer)'],\n",
       "       ['Hi', 'Grüß Gott',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #659813 (Esperantostern)'],\n",
       "       ['Run', 'Lauf',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #941078 (Fingerhut)'],\n",
       "       ...,\n",
       "       ['I wholeheartedly agree', 'Ich stimme rückhaltlos zu',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1488273 (Spamster) & #1693172 (al_ex_an_der)'],\n",
       "       ['I will always love you', 'Ich werde dich immer lieben',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #853146 (piksea) & #395302 (xtofu80)'],\n",
       "       ['I will be back by nine', 'Um neun bin ich wieder zurück',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #72281 (CK) & #345033 (lilygilder)']],\n",
       "      dtype='<U537')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deu_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert to lowercase\n",
    "for i in range(len(deu_eng)):\n",
    "    deu_eng[i,0] = deu_eng[i,0].lower()\n",
    "    \n",
    "    deu_eng[i,1] = deu_eng[i,1].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['hi', 'hallo',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #380701 (cburgmer)'],\n",
       "       ['hi', 'grüß gott',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #659813 (Esperantostern)'],\n",
       "       ['run', 'lauf',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #941078 (Fingerhut)'],\n",
       "       ...,\n",
       "       ['i wholeheartedly agree', 'ich stimme rückhaltlos zu',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #1488273 (Spamster) & #1693172 (al_ex_an_der)'],\n",
       "       ['i will always love you', 'ich werde dich immer lieben',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #853146 (piksea) & #395302 (xtofu80)'],\n",
       "       ['i will be back by nine', 'um neun bin ich wieder zurück',\n",
       "        'CC-BY 2.0 (France) Attribution: tatoeba.org #72281 (CK) & #345033 (lilygilder)']],\n",
       "      dtype='<U537')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deu_eng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text to Sequence Conversion\n",
    "\n",
    "To feed our data in a Seq2Seq model, we will have to convert both the input and the output sentences into integer sequences of fixed length. Before that, let's visualise the length of the sentences. We will capture the lengths of all the sentences in two separate lists for English and German, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty lists\n",
    "eng_l = []\n",
    "deu_l = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in deu_eng[:,0]:\n",
    "    eng_l.append(len(i.split()))\n",
    "\n",
    "for i in deu_eng[:,1]:\n",
    "    deu_l.append(len(i.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_df = pd.DataFrame({'eng':eng_l, 'deu':deu_l})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum length of the German sentences is 11 and that of the English phrases is 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's vectorize our text data by using Keras's Tokenizer() class. It will turn our sentences into sequences of integers. Then we will pad those sequences with zeros to make all the sequences of same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to build a tokenizer\n",
    "def tokenization(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 6361\n"
     ]
    }
   ],
   "source": [
    "# prepare english tokenizer\n",
    "eng_tokenizer = tokenization(deu_eng[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "\n",
    "eng_length = 8\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deutch Vocabulary Size: 10597\n"
     ]
    }
   ],
   "source": [
    "# prepare Deutch tokenizer\n",
    "deu_tokenizer = tokenization(deu_eng[:, 1])\n",
    "deu_vocab_size = len(deu_tokenizer.word_index) + 1\n",
    "\n",
    "deu_length = 8\n",
    "print('Deutch Vocabulary Size: %d' % deu_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given below is a function to prepare the sequences. It will also perform sequence padding to a maximum sentence length as mentioned above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and pad sequences\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "    # integer encode sequences\n",
    "    seq = tokenizer.texts_to_sequences(lines)\n",
    "    # pad sequences with 0 values\n",
    "    seq = pad_sequences(seq, maxlen=length, padding='post')\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now split the data into train and test set for model training and evaluation, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(deu_eng, test_size=0.2, random_state = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to encode the sentences. We will encode German sentences as the input sequences and English sentences as the target sequences. It will be done for both train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare training data\n",
    "trainX = encode_sequences(deu_tokenizer, deu_length, train[:, 1])\n",
    "trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare validation data\n",
    "testX = encode_sequences(deu_tokenizer, deu_length, test[:, 1])\n",
    "testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now comes the exciting part! Let us define our Seq2Seq model architecture. We are using an Embedding layer and an LSTM layer as our encoder and another LSTM layer followed by a Dense layer as the decoder.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build NMT model\n",
    "def build_model(in_vocab, out_vocab, in_timesteps, out_timesteps, units):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n",
    "    model.add(LSTM(units))\n",
    "    model.add(RepeatVector(out_timesteps))\n",
    "    model.add(LSTM(units, return_sequences=True))\n",
    "    model.add(Dense(out_vocab, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using RMSprop optimizer in this model as it is usually a good choice for recurrent neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nyjoey/anaconda3/envs/temporary/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/nyjoey/anaconda3/envs/temporary/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/nyjoey/anaconda3/envs/temporary/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/nyjoey/anaconda3/envs/temporary/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2974: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/nyjoey/anaconda3/envs/temporary/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/nyjoey/anaconda3/envs/temporary/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = build_model(deu_vocab_size, eng_vocab_size, deu_length, eng_length, 512)\n",
    "rms = optimizers.RMSprop(lr=0.001)\n",
    "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that we have used __'sparse_categorical_crossentropy'__ as the loss function because it allows us to use the target sequence as it is instead of one hot encoded format. One hot encoding the target sequences with such a huge vocabulary might consume our system's entire memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems we are all set to start training our model. We will train it for 30 epochs and with a batch size of 512. You may change and play these hyperparameters. We will also be using __ModelCheckpoint()__ to save the best model with lowest validation loss. I personally prefer this method over early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nyjoey/anaconda3/envs/temporary/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/30\n",
      "32000/32000 [==============================] - 163s 5ms/step - loss: 3.5196 - val_loss: 2.9651\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.96508, saving model to model.h1.24_jan_19\n",
      "Epoch 2/30\n",
      "32000/32000 [==============================] - 170s 5ms/step - loss: 2.8612 - val_loss: 2.8555\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.96508 to 2.85546, saving model to model.h1.24_jan_19\n",
      "Epoch 3/30\n",
      "32000/32000 [==============================] - 169s 5ms/step - loss: 2.6880 - val_loss: 2.6592\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.85546 to 2.65923, saving model to model.h1.24_jan_19\n",
      "Epoch 4/30\n",
      "32000/32000 [==============================] - 169s 5ms/step - loss: 2.5147 - val_loss: 2.5287\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.65923 to 2.52874, saving model to model.h1.24_jan_19\n",
      "Epoch 5/30\n",
      "32000/32000 [==============================] - 170s 5ms/step - loss: 2.3575 - val_loss: 2.4040\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.52874 to 2.40398, saving model to model.h1.24_jan_19\n",
      "Epoch 6/30\n",
      "32000/32000 [==============================] - 174s 5ms/step - loss: 2.2190 - val_loss: 2.3237\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.40398 to 2.32368, saving model to model.h1.24_jan_19\n",
      "Epoch 7/30\n",
      "32000/32000 [==============================] - 172s 5ms/step - loss: 2.0976 - val_loss: 2.2284\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.32368 to 2.22844, saving model to model.h1.24_jan_19\n",
      "Epoch 8/30\n",
      "32000/32000 [==============================] - 172s 5ms/step - loss: 1.9809 - val_loss: 2.1427\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.22844 to 2.14266, saving model to model.h1.24_jan_19\n",
      "Epoch 9/30\n",
      "32000/32000 [==============================] - 174s 5ms/step - loss: 1.8655 - val_loss: 2.0611\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.14266 to 2.06111, saving model to model.h1.24_jan_19\n",
      "Epoch 10/30\n",
      "32000/32000 [==============================] - 176s 5ms/step - loss: 1.7541 - val_loss: 1.9884\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.06111 to 1.98841, saving model to model.h1.24_jan_19\n",
      "Epoch 11/30\n",
      "32000/32000 [==============================] - 178s 6ms/step - loss: 1.6459 - val_loss: 1.9179\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.98841 to 1.91790, saving model to model.h1.24_jan_19\n",
      "Epoch 12/30\n",
      "32000/32000 [==============================] - 176s 6ms/step - loss: 1.5505 - val_loss: 1.8429\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.91790 to 1.84291, saving model to model.h1.24_jan_19\n",
      "Epoch 13/30\n",
      "32000/32000 [==============================] - 177s 6ms/step - loss: 1.4527 - val_loss: 1.7822\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.84291 to 1.78219, saving model to model.h1.24_jan_19\n",
      "Epoch 14/30\n",
      "32000/32000 [==============================] - 178s 6ms/step - loss: 1.3642 - val_loss: 1.7311\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.78219 to 1.73108, saving model to model.h1.24_jan_19\n",
      "Epoch 15/30\n",
      "32000/32000 [==============================] - 181s 6ms/step - loss: 1.2787 - val_loss: 1.6968\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.73108 to 1.69675, saving model to model.h1.24_jan_19\n",
      "Epoch 16/30\n",
      "32000/32000 [==============================] - 176s 5ms/step - loss: 1.1969 - val_loss: 1.6570\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.69675 to 1.65698, saving model to model.h1.24_jan_19\n",
      "Epoch 17/30\n",
      "32000/32000 [==============================] - 183s 6ms/step - loss: 1.1201 - val_loss: 1.6321\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.65698 to 1.63206, saving model to model.h1.24_jan_19\n",
      "Epoch 18/30\n",
      "32000/32000 [==============================] - 180s 6ms/step - loss: 1.0444 - val_loss: 1.5808\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.63206 to 1.58075, saving model to model.h1.24_jan_19\n",
      "Epoch 19/30\n",
      "32000/32000 [==============================] - 182s 6ms/step - loss: 0.9747 - val_loss: 1.5424\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.58075 to 1.54236, saving model to model.h1.24_jan_19\n",
      "Epoch 20/30\n",
      "32000/32000 [==============================] - 185s 6ms/step - loss: 0.9071 - val_loss: 1.5130\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.54236 to 1.51297, saving model to model.h1.24_jan_19\n",
      "Epoch 21/30\n",
      "32000/32000 [==============================] - 185s 6ms/step - loss: 0.8435 - val_loss: 1.5024\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.51297 to 1.50241, saving model to model.h1.24_jan_19\n",
      "Epoch 22/30\n",
      "32000/32000 [==============================] - 183s 6ms/step - loss: 0.7831 - val_loss: 1.4672\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.50241 to 1.46715, saving model to model.h1.24_jan_19\n",
      "Epoch 23/30\n",
      "32000/32000 [==============================] - 188s 6ms/step - loss: 0.7249 - val_loss: 1.4544\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.46715 to 1.45437, saving model to model.h1.24_jan_19\n",
      "Epoch 24/30\n",
      "32000/32000 [==============================] - 188s 6ms/step - loss: 0.6691 - val_loss: 1.4386\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.45437 to 1.43858, saving model to model.h1.24_jan_19\n",
      "Epoch 25/30\n",
      "32000/32000 [==============================] - 189s 6ms/step - loss: 0.6198 - val_loss: 1.4292\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.43858 to 1.42919, saving model to model.h1.24_jan_19\n",
      "Epoch 26/30\n",
      "32000/32000 [==============================] - 185s 6ms/step - loss: 0.5690 - val_loss: 1.4159\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.42919 to 1.41590, saving model to model.h1.24_jan_19\n",
      "Epoch 27/30\n",
      "32000/32000 [==============================] - 183s 6ms/step - loss: 0.5247 - val_loss: 1.4093\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.41590 to 1.40926, saving model to model.h1.24_jan_19\n",
      "Epoch 28/30\n",
      "32000/32000 [==============================] - 187s 6ms/step - loss: 0.4810 - val_loss: 1.3899\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.40926 to 1.38993, saving model to model.h1.24_jan_19\n",
      "Epoch 29/30\n",
      "32000/32000 [==============================] - 185s 6ms/step - loss: 0.4407 - val_loss: 1.3930\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.38993\n",
      "Epoch 30/30\n",
      "27136/32000 [========================>.....] - ETA: 26s - loss: 0.4012"
     ]
    }
   ],
   "source": [
    "filename = 'model.h1.24_jan_19'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1), \n",
    "          epochs=30, batch_size=512, \n",
    "          validation_split = 0.2,\n",
    "          callbacks=[checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the training loss and the validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['train','validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the saved model to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model.h1.24_jan_19')\n",
    "preds = model.predict_classes(testX.reshape((testX.shape[0],testX.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word(n, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == n:\n",
    "            return word\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert predictions into text (English)\n",
    "preds_text = []\n",
    "for i in preds:\n",
    "    temp = []\n",
    "    for j in range(len(i)):\n",
    "        t = get_word(i[j], eng_tokenizer)\n",
    "        if j > 0:\n",
    "            if (t == get_word(i[j-1], eng_tokenizer)) or (t == None):\n",
    "                temp.append('')\n",
    "            else:\n",
    "                temp.append(t)\n",
    "             \n",
    "        else:\n",
    "            if(t == None):\n",
    "                temp.append('')\n",
    "            else:\n",
    "                temp.append(t)            \n",
    "        \n",
    "    preds_text.append(' '.join(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({'actual' : test[:,0], 'predicted' : preds_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
